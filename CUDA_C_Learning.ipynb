{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMrWgXfkSNsX6fPG1NMIACl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sklow/google-colaboratory/blob/main/CUDA_C_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA C の練習\n",
        "- CUDA C プロフェッショナル プログラミングを使用"
      ],
      "metadata": {
        "id": "d7lykAectq57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "! をつけることで、bashの実行"
      ],
      "metadata": {
        "id": "S3yHE6GKt3UU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONP9__-wmXeb",
        "outputId": "d71df878-990f-4db1-9c1e-743dfc92b900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda/bin/nvcc\n"
          ]
        }
      ],
      "source": [
        "!which nvcc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjAjhmj140xS",
        "outputId": "48928bdb-a870-4028-c2fd-2f032c85aced"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "google colab 上のjupyter notebook でnvccを使えるようにする"
      ],
      "metadata": {
        "id": "WaXElezjsRDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rSl_twRnYMe",
        "outputId": "ab730ff5-2136-43e2-e06b-55a556b871ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-u8llt90u\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-u8llt90u\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4294 sha256=efbe42dc3cffb95b9fa5042cd94a1fb832f44182e0df3c73f705a13fd5b1b618\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_0lh3p76/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoT2vsPhsDWT",
        "outputId": "e3dd4060-8f95-42e7-8f6f-27b185c32022"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUDA samplesのヘッダーファイル活用.\n",
        "checkCudaErrors関数等があるヘッダーファイル(helper_cuda.h)をインストールする。"
      ],
      "metadata": {
        "id": "xHaZbslgs7iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-samples/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zw_yLCzsaKF",
        "outputId": "f3a788c2-31a4-4fe5-9280-821a1166f9dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cuda-samples'...\n",
            "remote: Enumerating objects: 17263, done.\u001b[K\n",
            "remote: Counting objects: 100% (17263/17263), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2115/2115), done.\u001b[K\n",
            "remote: Total 17263 (delta 15225), reused 17041 (delta 15116), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (17263/17263), 132.94 MiB | 25.66 MiB/s, done.\n",
            "Resolving deltas: 100% (15225/15225), done.\n",
            "Updating files: 100% (3998/3998), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r cuda-samples/Common/* /usr/local/include"
      ],
      "metadata": {
        "id": "ku2H-LxUsqsT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%writefile temp.cpp で ファイル書き込みができる  \n",
        "まず、参考書のcommon.hを用意する"
      ],
      "metadata": {
        "id": "1RtqLSJztQtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /usr/local/common"
      ],
      "metadata": {
        "id": "s7XjjjAzxJdG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /usr/local/common/common.h\n",
        "#include <sys/time.h>\n",
        "\n",
        "#ifndef _COMMON_H\n",
        "#define _COMMON_H\n",
        "\n",
        "#define CHECK(call)                                                            \\\n",
        "{                                                                              \\\n",
        "    cudaError_t error = call;                                            \\\n",
        "    if (error != cudaSuccess)                                                  \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n",
        "        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n",
        "                cudaGetErrorString(error));                                    \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CUBLAS(call)                                                     \\\n",
        "{                                                                              \\\n",
        "    cublasStatus_t err;                                                        \\\n",
        "    if ((err = (call)) != CUBLAS_STATUS_SUCCESS)                               \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got CUBLAS error %d at %s:%d\\n\", err, __FILE__,       \\\n",
        "                __LINE__);                                                     \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CURAND(call)                                                     \\\n",
        "{                                                                              \\\n",
        "    curandStatus_t err;                                                        \\\n",
        "    if ((err = (call)) != CURAND_STATUS_SUCCESS)                               \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got CURAND error %d at %s:%d\\n\", err, __FILE__,       \\\n",
        "                __LINE__);                                                     \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CUFFT(call)                                                      \\\n",
        "{                                                                              \\\n",
        "    cufftResult err;                                                           \\\n",
        "    if ( (err = (call)) != CUFFT_SUCCESS)                                      \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got CUFFT error %d at %s:%d\\n\", err, __FILE__,        \\\n",
        "                __LINE__);                                                     \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CUSPARSE(call)                                                   \\\n",
        "{                                                                              \\\n",
        "    cusparseStatus_t err;                                                      \\\n",
        "    if ((err = (call)) != CUSPARSE_STATUS_SUCCESS)                             \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got error %d at %s:%d\\n\", err, __FILE__, __LINE__);   \\\n",
        "        cudaError_t cuda_err = cudaGetLastError();                             \\\n",
        "        if (cuda_err != cudaSuccess)                                           \\\n",
        "        {                                                                      \\\n",
        "            fprintf(stderr, \"  CUDA error \\\"%s\\\" also detected\\n\",             \\\n",
        "                    cudaGetErrorString(cuda_err));                             \\\n",
        "        }                                                                      \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "inline double seconds()\n",
        "{\n",
        "    struct timeval tp;\n",
        "    struct timezone tzp;\n",
        "    int i = gettimeofday(&tp, &tzp);\n",
        "    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n",
        "}\n",
        "\n",
        "#endif // _COMMON_H\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDT_3I5Wv83R",
        "outputId": "af77fbea-fa79-447e-8a59-464cbd413ed8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /usr/local/common/common.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /usr/local/common/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph7-XgWdtnxp",
        "outputId": "0558dae1-f2bc-45ab-8e4c-5906f49ac841"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include \"../common/common.h\"\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * A simple introduction to programming in CUDA. This program prints \"Hello\n",
        " * World from GPU! from 10 CUDA threads running on the GPU.\n",
        " */\n",
        "\n",
        "__global__ void helloFromGPU()\n",
        "{\n",
        "    printf(\"Hello World from GPU! \\n\");\n",
        "    printf(\"thread: {%d}\\n\", threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    printf(\"Hello World from CPU!\\n\");\n",
        "\n",
        "    helloFromGPU<<<1, 10>>>();\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1b7POsTsv1z",
        "outputId": "dd23b238-d95b-4cc4-aa99-eaab40fc9590"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World from CPU!\n",
            "Hello World from GPU! \n",
            "Hello World from GPU! \n",
            "Hello World from GPU! \n",
            "Hello World from GPU! \n",
            "Hello World from GPU! \n",
            "Hello World from GPU! \n",
            "Hello World from GPU! \n",
            "Hello World from GPU! \n",
            "Hello World from GPU! \n",
            "Hello World from GPU! \n",
            "thread: {0}\n",
            "thread: {1}\n",
            "thread: {2}\n",
            "thread: {3}\n",
            "thread: {4}\n",
            "thread: {5}\n",
            "thread: {6}\n",
            "thread: {7}\n",
            "thread: {8}\n",
            "thread: {9}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include \"../common/common.h\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Display the dimensionality of a thread block and grid from the host and\n",
        " * device.\n",
        " */\n",
        "\n",
        "__global__ void checkIndex(void)\n",
        "{\n",
        "    printf(\"threadIdx:(%d, %d, %d)\\tblockIdx:(%d, %d, %d)\\tblockDim:(%d, %d, %d)\\tgridDim:(%d, %d, %d)\\n\", threadIdx.x, threadIdx.y, threadIdx.z,blockIdx.x, blockIdx.y, blockIdx.z, blockDim.x, blockDim.y, blockDim.z, gridDim.x, gridDim.y, gridDim.z);\n",
        "\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    // define total data element\n",
        "    int nElem = 6;\n",
        "\n",
        "    // define grid and block structure\n",
        "    dim3 block(3);\n",
        "    dim3 grid((nElem + block.x - 1) / block.x);\n",
        "\n",
        "    // check grid and block dimension from host side\n",
        "    printf(\"grid.x %d grid.y %d grid.z %d\\n\", grid.x, grid.y, grid.z);\n",
        "    printf(\"block.x %d block.y %d block.z %d\\n\", block.x, block.y, block.z);\n",
        "\n",
        "    // check grid and block dimension from device side\n",
        "    checkIndex<<<grid, block>>>();\n",
        "\n",
        "    // reset device before you leave\n",
        "    CHECK(cudaDeviceReset());\n",
        "\n",
        "    return(0);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loWfTMHWkoje",
        "outputId": "4a6af14d-0e26-46e4-f40f-77e9b3f34b95"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid.x 2 grid.y 1 grid.z 1\n",
            "block.x 3 block.y 1 block.z 1\n",
            "threadIdx:(0, 0, 0)\tblockIdx:(0, 0, 0)\tblockDim:(3, 1, 1)\tgridDim:(2, 1, 1)\n",
            "threadIdx:(1, 0, 0)\tblockIdx:(0, 0, 0)\tblockDim:(3, 1, 1)\tgridDim:(2, 1, 1)\n",
            "threadIdx:(2, 0, 0)\tblockIdx:(0, 0, 0)\tblockDim:(3, 1, 1)\tgridDim:(2, 1, 1)\n",
            "threadIdx:(0, 0, 0)\tblockIdx:(1, 0, 0)\tblockDim:(3, 1, 1)\tgridDim:(2, 1, 1)\n",
            "threadIdx:(1, 0, 0)\tblockIdx:(1, 0, 0)\tblockDim:(3, 1, 1)\tgridDim:(2, 1, 1)\n",
            "threadIdx:(2, 0, 0)\tblockIdx:(1, 0, 0)\tblockDim:(3, 1, 1)\tgridDim:(2, 1, 1)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include \"../common/common.h\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * This example demonstrates a simple vector sum on the GPU and on the host.\n",
        " * sumArraysOnGPU splits the work of the vector sum across CUDA threads on the\n",
        " * GPU. Only a single thread block is used in this small case, for simplicity.\n",
        " * sumArraysOnHost sequentially iterates through vector elements on the host.\n",
        " */\n",
        "\n",
        "void checkResult(float *hostRef, float *gpuRef, const int N)\n",
        "{\n",
        "    double epsilon = 1.0E-8;\n",
        "    bool match = 1;\n",
        "\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        if (abs(hostRef[i] - gpuRef[i]) > epsilon)\n",
        "        {\n",
        "            match = 0;\n",
        "            printf(\"Arrays do not match!\\n\");\n",
        "            printf(\"host %5.2f gpu %5.2f at current %d\\n\", hostRef[i],\n",
        "                   gpuRef[i], i);\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (match) printf(\"Arrays match.\\n\\n\");\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "\n",
        "void initialData(float *ip, int size)\n",
        "{\n",
        "    // generate different seed for random number\n",
        "    time_t t;\n",
        "    srand((unsigned) time(&t));\n",
        "\n",
        "    for (int i = 0; i < size; i++)\n",
        "    {\n",
        "        ip[i] = (float)(rand() & 0xFF) / 10.0f;\n",
        "    }\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "\n",
        "void sumArraysOnHost(float *A, float *B, float *C, const int N)\n",
        "{\n",
        "    for (int idx = 0; idx < N; idx++)\n",
        "        C[idx] = A[idx] + B[idx];\n",
        "}\n",
        "\n",
        "__global__ void sumArraysOnGPU(float *A, float *B, float *C, const int N)\n",
        "{\n",
        "    int i = threadIdx.x;\n",
        "\n",
        "    //if (i < N)\n",
        "    C[i] = A[i] + B[i];\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    printf(\"%s Starting...\\n\", argv[0]);\n",
        "\n",
        "    // set up device\n",
        "    int dev = 0;\n",
        "    CHECK(cudaSetDevice(dev));\n",
        "\n",
        "    // set up data size of vectors\n",
        "    int nElem = 1 << 5;\n",
        "    printf(\"Vector size %d\\n\", nElem);\n",
        "\n",
        "    // malloc host memory\n",
        "    size_t nBytes = nElem * sizeof(float);\n",
        "\n",
        "    float *h_A, *h_B, *hostRef, *gpuRef;\n",
        "    h_A     = (float *)malloc(nBytes);\n",
        "    h_B     = (float *)malloc(nBytes);\n",
        "    hostRef = (float *)malloc(nBytes);\n",
        "    gpuRef  = (float *)malloc(nBytes);\n",
        "\n",
        "    // initialize data at host side\n",
        "    initialData(h_A, nElem);\n",
        "    initialData(h_B, nElem);\n",
        "\n",
        "    memset(hostRef, 0, nBytes);\n",
        "    memset(gpuRef,  0, nBytes);\n",
        "\n",
        "    // malloc device global memory\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    CHECK(cudaMalloc((float**)&d_A, nBytes));\n",
        "    CHECK(cudaMalloc((float**)&d_B, nBytes));\n",
        "    CHECK(cudaMalloc((float**)&d_C, nBytes));\n",
        "\n",
        "    // transfer data from host to device\n",
        "    CHECK(cudaMemcpy(d_A, h_A, nBytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaMemcpy(d_B, h_B, nBytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaMemcpy(d_C, gpuRef, nBytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // invoke kernel at host side\n",
        "    dim3 block (nElem);\n",
        "    dim3 grid  (1);\n",
        "\n",
        "    sumArraysOnGPU<<<grid, block>>>(d_A, d_B, d_C, nElem);\n",
        "    printf(\"Execution configure <<<%d, %d>>>\\n\", grid.x, block.x);\n",
        "\n",
        "    // copy kernel result back to host side\n",
        "    CHECK(cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // add vector at host side for result checks\n",
        "    sumArraysOnHost(h_A, h_B, hostRef, nElem);\n",
        "\n",
        "    // check device results\n",
        "    checkResult(hostRef, gpuRef, nElem);\n",
        "\n",
        "    // free device global memory\n",
        "    CHECK(cudaFree(d_A));\n",
        "    CHECK(cudaFree(d_B));\n",
        "    CHECK(cudaFree(d_C));\n",
        "\n",
        "    // free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(hostRef);\n",
        "    free(gpuRef);\n",
        "\n",
        "    CHECK(cudaDeviceReset());\n",
        "    return(0);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOTxsdLfoKVY",
        "outputId": "bba46b00-8de4-4975-e157-e70bc56130a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/tmpj6ng_09h/55fd04e0-bc0a-456e-b09e-e42eb3a62a1e.out Starting...\n",
            "Vector size 32\n",
            "Execution configure <<<1, 32>>>\n",
            "Arrays match.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile timer.cu\n",
        "\n",
        "#include \"../common/common.h\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#include<math.h>\n",
        "\n",
        "/*\n",
        " * This example demonstrates a simple vector sum on the GPU and on the host.\n",
        " * sumArraysOnGPU splits the work of the vector sum across CUDA threads on the\n",
        " * GPU. Only a single thread block is used in this small case, for simplicity.\n",
        " * sumArraysOnHost sequentially iterates through vector elements on the host.\n",
        " * This version of sumArrays adds host timers to measure GPU and CPU\n",
        " * performance.\n",
        " */\n",
        "\n",
        "void checkResult(float *hostRef, float *gpuRef, const int N)\n",
        "{\n",
        "    double epsilon = 1.0E-8;\n",
        "    bool match = 1;\n",
        "\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        if (abs(hostRef[i] - gpuRef[i]) > epsilon)\n",
        "        {\n",
        "            match = 0;\n",
        "            printf(\"Arrays do not match!\\n\");\n",
        "            printf(\"host %5.2f gpu %5.2f at current %d\\n\", hostRef[i],\n",
        "                   gpuRef[i], i);\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (match) printf(\"Arrays match.\\n\\n\");\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "void initialData(float *ip, int size)\n",
        "{\n",
        "    // generate different seed for random number\n",
        "    time_t t;\n",
        "    srand((unsigned) time(&t));\n",
        "\n",
        "    for (int i = 0; i < size; i++)\n",
        "    {\n",
        "        ip[i] = (float)( rand() & 0xFF ) / 10.0f;\n",
        "    }\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "void sumArraysOnHost(float *A, float *B, float *C, const int N)\n",
        "{\n",
        "    for (int idx = 0; idx < N; idx++)\n",
        "    {\n",
        "        C[idx] = A[idx] + B[idx];\n",
        "    }\n",
        "}\n",
        "__global__ void sumArraysOnGPU(float *A, float *B, float *C, const int N)\n",
        "{\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (i < N) C[i] = A[i] + B[i];\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    printf(\"%s Starting...\\n\", argv[0]);\n",
        "\n",
        "    // set up device\n",
        "    int dev = 0;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
        "    printf(\"Using Device %d: %s\\n\", dev, deviceProp.name);\n",
        "    CHECK(cudaSetDevice(dev));\n",
        "\n",
        "    // set up data size of vectors\n",
        "    int nElem = 1 << 24;\n",
        "    printf(\"Vector size %d\\n\", nElem);\n",
        "\n",
        "    // malloc host memory\n",
        "    size_t nBytes = nElem * sizeof(float);\n",
        "\n",
        "    float *h_A, *h_B, *hostRef, *gpuRef;\n",
        "    h_A     = (float *)malloc(nBytes);\n",
        "    h_B     = (float *)malloc(nBytes);\n",
        "    hostRef = (float *)malloc(nBytes);\n",
        "    gpuRef  = (float *)malloc(nBytes);\n",
        "\n",
        "    double iStart, iElaps;\n",
        "\n",
        "    // initialize data at host side\n",
        "    iStart = seconds();\n",
        "    initialData(h_A, nElem);\n",
        "    initialData(h_B, nElem);\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"initialData Time elapsed %f sec\\n\", iElaps);\n",
        "    memset(hostRef, 0, nBytes);\n",
        "    memset(gpuRef,  0, nBytes);\n",
        "\n",
        "    // add vector at host side for result checks\n",
        "    iStart = seconds();\n",
        "    sumArraysOnHost(h_A, h_B, hostRef, nElem);\n",
        "    float cpuElaps = seconds() - iStart;\n",
        "    printf(\"sumArraysOnHost Time elapsed %f sec\\n\", cpuElaps);\n",
        "\n",
        "    // malloc device global memory\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    CHECK(cudaMalloc((float**)&d_A, nBytes));\n",
        "    CHECK(cudaMalloc((float**)&d_B, nBytes));\n",
        "    CHECK(cudaMalloc((float**)&d_C, nBytes));\n",
        "\n",
        "    // transfer data from host to device\n",
        "    CHECK(cudaMemcpy(d_A, h_A, nBytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaMemcpy(d_B, h_B, nBytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaMemcpy(d_C, gpuRef, nBytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // invoke kernel at host side\n",
        "\n",
        "    for(int i=1; i<2; i++)\n",
        "    {\n",
        "        int iLen = 1024;\n",
        "        dim3 block (iLen);\n",
        "        dim3 grid  ((nElem + block.x - 1) / block.x);\n",
        "\n",
        "        iStart = seconds();\n",
        "        sumArraysOnGPU<<<grid, block>>>(d_A, d_B, d_C, nElem);\n",
        "        CHECK(cudaDeviceSynchronize());\n",
        "        float gpuElaps = seconds() - iStart;\n",
        "        printf(\"sumArraysOnGPU <<<  %d, %d  >>>  Time elapsed %f sec\\n\", grid.x,\n",
        "           block.x, gpuElaps);\n",
        "\n",
        "        printf(\"speed scale (gpu/cpu) %f \\n\", (float)(cpuElaps/gpuElaps));\n",
        "    }\n",
        "\n",
        "    // check kernel error\n",
        "    CHECK(cudaGetLastError()) ;\n",
        "\n",
        "    // copy kernel result back to host side\n",
        "    CHECK(cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // check device results\n",
        "    checkResult(hostRef, gpuRef, nElem);\n",
        "\n",
        "    // free device global memory\n",
        "    CHECK(cudaFree(d_A));\n",
        "    CHECK(cudaFree(d_B));\n",
        "    CHECK(cudaFree(d_C));\n",
        "\n",
        "    // free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(hostRef);\n",
        "    free(gpuRef);\n",
        "\n",
        "    return(0);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_bEHCUEuutz",
        "outputId": "645f4b6d-b03d-4945-abfa-217341424ea1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing timer.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc timer.cu -o timer"
      ],
      "metadata": {
        "id": "szJISGpV9u2I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./timer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alGJ8S8N-T_b",
        "outputId": "45edc30f-d9e3-416e-b827-eaaee9237e59"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./timer Starting...\n",
            "==749== NVPROF is profiling process 749, command: ./timer\n",
            "Using Device 0: Tesla T4\n",
            "Vector size 16777216\n",
            "initialData Time elapsed 0.702956 sec\n",
            "sumArraysOnHost Time elapsed 0.055440 sec\n",
            "sumArraysOnGPU <<<  16384, 1024  >>>  Time elapsed 0.000979 sec\n",
            "speed scale (gpu/cpu) 56.632244 \n",
            "Arrays match.\n",
            "\n",
            "==749== Profiling application: ./timer\n",
            "==749== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   74.08%  42.895ms         3  14.298ms  14.203ms  14.427ms  [CUDA memcpy HtoD]\n",
            "                   24.39%  14.124ms         1  14.124ms  14.124ms  14.124ms  [CUDA memcpy DtoH]\n",
            "                    1.52%  882.08us         1  882.08us  882.08us  882.08us  sumArraysOnGPU(float*, float*, float*, int)\n",
            "      API calls:   80.10%  257.11ms         3  85.703ms  136.12us  256.82ms  cudaMalloc\n",
            "                   18.08%  58.030ms         4  14.507ms  14.439ms  14.609ms  cudaMemcpy\n",
            "                    1.09%  3.5003ms         3  1.1668ms  242.33us  2.1445ms  cudaFree\n",
            "                    0.35%  1.1311ms         1  1.1311ms  1.1311ms  1.1311ms  cuDeviceGetPCIBusId\n",
            "                    0.29%  934.48us         1  934.48us  934.48us  934.48us  cudaDeviceSynchronize\n",
            "                    0.04%  114.15us       101  1.1300us     133ns  45.390us  cuDeviceGetAttribute\n",
            "                    0.03%  83.347us         1  83.347us  83.347us  83.347us  cudaGetDeviceProperties\n",
            "                    0.01%  39.140us         1  39.140us  39.140us  39.140us  cudaLaunchKernel\n",
            "                    0.01%  33.594us         1  33.594us  33.594us  33.594us  cuDeviceGetName\n",
            "                    0.01%  21.939us         1  21.939us  21.939us  21.939us  cudaSetDevice\n",
            "                    0.00%  1.7450us         3     581ns     275ns  1.1500us  cuDeviceGetCount\n",
            "                    0.00%  1.0660us         2     533ns     334ns     732ns  cuDeviceGet\n",
            "                    0.00%  1.0200us         1  1.0200us  1.0200us  1.0200us  cudaGetLastError\n",
            "                    0.00%     447ns         1     447ns     447ns     447ns  cuModuleGetLoadingMode\n",
            "                    0.00%     396ns         1     396ns     396ns     396ns  cuDeviceTotalMem\n",
            "                    0.00%     217ns         1     217ns     217ns     217ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include \"../common/common.h\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * This example helps to visualize the relationship between thread/block IDs and\n",
        " * offsets into data. For each CUDA thread, this example displays the\n",
        " * intra-block thread ID, the inter-block block ID, the global coordinate of a\n",
        " * thread, the calculated offset into input data, and the input data at that\n",
        " * offset.\n",
        " */\n",
        "\n",
        "void printMatrix(int *C, const int nx, const int ny)\n",
        "{\n",
        "    int *ic = C;\n",
        "    printf(\"\\nMatrix: (%d.%d)\\n\", nx, ny);\n",
        "\n",
        "    for (int iy = 0; iy < ny; iy++)\n",
        "    {\n",
        "        for (int ix = 0; ix < nx; ix++)\n",
        "        {\n",
        "            printf(\"%3d\", ic[ix]);\n",
        "\n",
        "        }\n",
        "\n",
        "        ic += nx;\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"\\n\");\n",
        "    return;\n",
        "}\n",
        "\n",
        "__global__ void printThreadIndex(int *A, const int nx, const int ny)\n",
        "{\n",
        "    int ix = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int iy = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    unsigned int idx = iy * nx + ix;\n",
        "\n",
        "    printf(\"thread_id (%d,%d) block_id (%d,%d) coordinate (%d,%d) global index\"\n",
        "           \" %2d ival %2d\\n\", threadIdx.x, threadIdx.y, blockIdx.x, blockIdx.y,\n",
        "           ix, iy, idx, A[idx]);\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    printf(\"%s Starting...\\n\", argv[0]);\n",
        "\n",
        "    // get device information\n",
        "    int dev = 0;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
        "    printf(\"Using Device %d: %s\\n\", dev, deviceProp.name);\n",
        "    CHECK(cudaSetDevice(dev));\n",
        "\n",
        "    // set matrix dimension\n",
        "    int nx = 8;\n",
        "    int ny = 6;\n",
        "    int nxy = nx * ny;\n",
        "    int nBytes = nxy * sizeof(float);\n",
        "\n",
        "    // malloc host memory\n",
        "    int *h_A;\n",
        "    h_A = (int *)malloc(nBytes);\n",
        "\n",
        "    // iniitialize host matrix with integer\n",
        "    for (int i = 0; i < nxy; i++)\n",
        "    {\n",
        "        h_A[i] = i;\n",
        "    }\n",
        "    printMatrix(h_A, nx, ny);\n",
        "\n",
        "    // malloc device memory\n",
        "    int *d_MatA;\n",
        "    CHECK(cudaMalloc((void **)&d_MatA, nBytes));\n",
        "\n",
        "    // transfer data from host to device\n",
        "    CHECK(cudaMemcpy(d_MatA, h_A, nBytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // set up execution configuration\n",
        "    dim3 block(4, 2);\n",
        "    dim3 grid((nx + block.x - 1) / block.x, (ny + block.y - 1) / block.y);\n",
        "\n",
        "    // invoke the kernel\n",
        "    printThreadIndex<<<grid, block>>>(d_MatA, nx, ny);\n",
        "    CHECK(cudaGetLastError());\n",
        "\n",
        "    // free host and devide memory\n",
        "    CHECK(cudaFree(d_MatA));\n",
        "    free(h_A);\n",
        "\n",
        "    // reset device\n",
        "    CHECK(cudaDeviceReset());\n",
        "\n",
        "    return (0);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTVjM1XXl3t1",
        "outputId": "59bf2e26-717d-45e5-c660-a349f838ea3a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/tmpw55ey9pl/79608879-5ff5-49e7-b933-a08eacb60a84.out Starting...\n",
            "Using Device 0: Tesla T4\n",
            "\n",
            "Matrix: (8.6)\n",
            "  0  1  2  3  4  5  6  7\n",
            "  8  9 10 11 12 13 14 15\n",
            " 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31\n",
            " 32 33 34 35 36 37 38 39\n",
            " 40 41 42 43 44 45 46 47\n",
            "\n",
            "thread_id (0,0) block_id (0,1) coordinate (0,2) global index 16 ival 16\n",
            "thread_id (1,0) block_id (0,1) coordinate (1,2) global index 17 ival 17\n",
            "thread_id (2,0) block_id (0,1) coordinate (2,2) global index 18 ival 18\n",
            "thread_id (3,0) block_id (0,1) coordinate (3,2) global index 19 ival 19\n",
            "thread_id (0,1) block_id (0,1) coordinate (0,3) global index 24 ival 24\n",
            "thread_id (1,1) block_id (0,1) coordinate (1,3) global index 25 ival 25\n",
            "thread_id (2,1) block_id (0,1) coordinate (2,3) global index 26 ival 26\n",
            "thread_id (3,1) block_id (0,1) coordinate (3,3) global index 27 ival 27\n",
            "thread_id (0,0) block_id (1,2) coordinate (4,4) global index 36 ival 36\n",
            "thread_id (1,0) block_id (1,2) coordinate (5,4) global index 37 ival 37\n",
            "thread_id (2,0) block_id (1,2) coordinate (6,4) global index 38 ival 38\n",
            "thread_id (3,0) block_id (1,2) coordinate (7,4) global index 39 ival 39\n",
            "thread_id (0,1) block_id (1,2) coordinate (4,5) global index 44 ival 44\n",
            "thread_id (1,1) block_id (1,2) coordinate (5,5) global index 45 ival 45\n",
            "thread_id (2,1) block_id (1,2) coordinate (6,5) global index 46 ival 46\n",
            "thread_id (3,1) block_id (1,2) coordinate (7,5) global index 47 ival 47\n",
            "thread_id (0,0) block_id (0,0) coordinate (0,0) global index  0 ival  0\n",
            "thread_id (1,0) block_id (0,0) coordinate (1,0) global index  1 ival  1\n",
            "thread_id (2,0) block_id (0,0) coordinate (2,0) global index  2 ival  2\n",
            "thread_id (3,0) block_id (0,0) coordinate (3,0) global index  3 ival  3\n",
            "thread_id (0,1) block_id (0,0) coordinate (0,1) global index  8 ival  8\n",
            "thread_id (1,1) block_id (0,0) coordinate (1,1) global index  9 ival  9\n",
            "thread_id (2,1) block_id (0,0) coordinate (2,1) global index 10 ival 10\n",
            "thread_id (3,1) block_id (0,0) coordinate (3,1) global index 11 ival 11\n",
            "thread_id (0,0) block_id (0,2) coordinate (0,4) global index 32 ival 32\n",
            "thread_id (1,0) block_id (0,2) coordinate (1,4) global index 33 ival 33\n",
            "thread_id (2,0) block_id (0,2) coordinate (2,4) global index 34 ival 34\n",
            "thread_id (3,0) block_id (0,2) coordinate (3,4) global index 35 ival 35\n",
            "thread_id (0,1) block_id (0,2) coordinate (0,5) global index 40 ival 40\n",
            "thread_id (1,1) block_id (0,2) coordinate (1,5) global index 41 ival 41\n",
            "thread_id (2,1) block_id (0,2) coordinate (2,5) global index 42 ival 42\n",
            "thread_id (3,1) block_id (0,2) coordinate (3,5) global index 43 ival 43\n",
            "thread_id (0,0) block_id (1,1) coordinate (4,2) global index 20 ival 20\n",
            "thread_id (1,0) block_id (1,1) coordinate (5,2) global index 21 ival 21\n",
            "thread_id (2,0) block_id (1,1) coordinate (6,2) global index 22 ival 22\n",
            "thread_id (3,0) block_id (1,1) coordinate (7,2) global index 23 ival 23\n",
            "thread_id (0,1) block_id (1,1) coordinate (4,3) global index 28 ival 28\n",
            "thread_id (1,1) block_id (1,1) coordinate (5,3) global index 29 ival 29\n",
            "thread_id (2,1) block_id (1,1) coordinate (6,3) global index 30 ival 30\n",
            "thread_id (3,1) block_id (1,1) coordinate (7,3) global index 31 ival 31\n",
            "thread_id (0,0) block_id (1,0) coordinate (4,0) global index  4 ival  4\n",
            "thread_id (1,0) block_id (1,0) coordinate (5,0) global index  5 ival  5\n",
            "thread_id (2,0) block_id (1,0) coordinate (6,0) global index  6 ival  6\n",
            "thread_id (3,0) block_id (1,0) coordinate (7,0) global index  7 ival  7\n",
            "thread_id (0,1) block_id (1,0) coordinate (4,1) global index 12 ival 12\n",
            "thread_id (1,1) block_id (1,0) coordinate (5,1) global index 13 ival 13\n",
            "thread_id (2,1) block_id (1,0) coordinate (6,1) global index 14 ival 14\n",
            "thread_id (3,1) block_id (1,0) coordinate (7,1) global index 15 ival 15\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include \"../common/common.h\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * This example demonstrates a simple vector sum on the GPU and on the host.\n",
        " * sumArraysOnGPU splits the work of the vector sum across CUDA threads on the\n",
        " * GPU. A 2D thread block and 2D grid are used. sumArraysOnHost sequentially\n",
        " * iterates through vector elements on the host.\n",
        " */\n",
        "\n",
        "void initialData(float *ip, const int size)\n",
        "{\n",
        "    int i;\n",
        "\n",
        "    for(i = 0; i < size; i++)\n",
        "    {\n",
        "        ip[i] = (float)(rand() & 0xFF) / 10.0f;\n",
        "    }\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "void sumMatrixOnHost(float *A, float *B, float *C, const int nx,\n",
        "                     const int ny)\n",
        "{\n",
        "    float *ia = A;\n",
        "    float *ib = B;\n",
        "    float *ic = C;\n",
        "\n",
        "    for (int iy = 0; iy < ny; iy++)\n",
        "    {\n",
        "        for (int ix = 0; ix < nx; ix++)\n",
        "        {\n",
        "            ic[ix] = ia[ix] + ib[ix];\n",
        "\n",
        "        }\n",
        "\n",
        "        ia += nx;\n",
        "        ib += nx;\n",
        "        ic += nx;\n",
        "    }\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "\n",
        "void checkResult(float *hostRef, float *gpuRef, const int N)\n",
        "{\n",
        "    double epsilon = 1.0E-8;\n",
        "    bool match = 1;\n",
        "\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        if (abs(hostRef[i] - gpuRef[i]) > epsilon)\n",
        "        {\n",
        "            match = 0;\n",
        "            printf(\"host %f gpu %f\\n\", hostRef[i], gpuRef[i]);\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (match)\n",
        "        printf(\"Arrays match.\\n\\n\");\n",
        "    else\n",
        "        printf(\"Arrays do not match.\\n\\n\");\n",
        "}\n",
        "\n",
        "// grid 2D block 2D\n",
        "__global__ void sumMatrixOnGPU2D(float *MatA, float *MatB, float *MatC, int nx,\n",
        "                                 int ny)\n",
        "{\n",
        "    unsigned int ix = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    unsigned int iy = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    unsigned int idx = iy * nx + ix;\n",
        "\n",
        "    if (ix < nx && iy < ny)\n",
        "        MatC[idx] = MatA[idx] + MatB[idx];\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    printf(\"%s Starting...\\n\", argv[0]);\n",
        "\n",
        "    // set up device\n",
        "    int dev = 0;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
        "    printf(\"Using Device %d: %s\\n\", dev, deviceProp.name);\n",
        "    CHECK(cudaSetDevice(dev));\n",
        "\n",
        "    // set up data size of matrix\n",
        "    int nx = 1 << 14;\n",
        "    int ny = 1 << 14;\n",
        "\n",
        "    int nxy = nx * ny;\n",
        "    int nBytes = nxy * sizeof(float);\n",
        "    printf(\"Matrix size: nx %d ny %d\\n\", nx, ny);\n",
        "\n",
        "    // malloc host memory\n",
        "    float *h_A, *h_B, *hostRef, *gpuRef;\n",
        "    h_A = (float *)malloc(nBytes);\n",
        "    h_B = (float *)malloc(nBytes);\n",
        "    hostRef = (float *)malloc(nBytes);\n",
        "    gpuRef = (float *)malloc(nBytes);\n",
        "\n",
        "    // initialize data at host side\n",
        "    double iStart = seconds();\n",
        "    initialData(h_A, nxy);\n",
        "    initialData(h_B, nxy);\n",
        "    double iElaps = seconds() - iStart;\n",
        "    printf(\"Matrix initialization elapsed %f sec\\n\", iElaps);\n",
        "\n",
        "    memset(hostRef, 0, nBytes);\n",
        "    memset(gpuRef, 0, nBytes);\n",
        "\n",
        "    // add matrix at host side for result checks\n",
        "    iStart = seconds();\n",
        "    sumMatrixOnHost(h_A, h_B, hostRef, nx, ny);\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"sumMatrixOnHost elapsed %f sec\\n\", iElaps);\n",
        "\n",
        "    // malloc device global memory\n",
        "    float *d_MatA, *d_MatB, *d_MatC;\n",
        "    CHECK(cudaMalloc((void **)&d_MatA, nBytes));\n",
        "    CHECK(cudaMalloc((void **)&d_MatB, nBytes));\n",
        "    CHECK(cudaMalloc((void **)&d_MatC, nBytes));\n",
        "\n",
        "    // transfer data from host to device\n",
        "    CHECK(cudaMemcpy(d_MatA, h_A, nBytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaMemcpy(d_MatB, h_B, nBytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // invoke kernel at host side\n",
        "    int dimx = 32;\n",
        "    int dimy = 16;\n",
        "    dim3 block(dimx, dimy);\n",
        "    dim3 grid((nx + block.x - 1) / block.x, (ny + block.y - 1) / block.y);\n",
        "\n",
        "    iStart = seconds();\n",
        "    sumMatrixOnGPU2D<<<grid, block>>>(d_MatA, d_MatB, d_MatC, nx, ny);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"sumMatrixOnGPU2D <<<(%d,%d), (%d,%d)>>> elapsed %f sec\\n\", grid.x,\n",
        "           grid.y,\n",
        "           block.x, block.y, iElaps);\n",
        "    // check kernel error\n",
        "    CHECK(cudaGetLastError());\n",
        "\n",
        "    // copy kernel result back to host side\n",
        "    CHECK(cudaMemcpy(gpuRef, d_MatC, nBytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // check device results\n",
        "    checkResult(hostRef, gpuRef, nxy);\n",
        "\n",
        "    // free device global memory\n",
        "    CHECK(cudaFree(d_MatA));\n",
        "    CHECK(cudaFree(d_MatB));\n",
        "    CHECK(cudaFree(d_MatC));\n",
        "\n",
        "    // free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(hostRef);\n",
        "    free(gpuRef);\n",
        "\n",
        "    // reset device\n",
        "    CHECK(cudaDeviceReset());\n",
        "\n",
        "    return (0);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFS6Ao6DoeJ9",
        "outputId": "4c64b867-6fc4-44cc-c333-9917a8bd565d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/tmp9zqnjug_/d98fb41d-512e-4341-a06a-cd87d0e24099.out Starting...\n",
            "Using Device 0: Tesla T4\n",
            "Matrix size: nx 16384 ny 16384\n",
            "Matrix initialization elapsed 11.653740 sec\n",
            "sumMatrixOnHost elapsed 0.941889 sec\n",
            "sumMatrixOnGPU2D <<<(512,1024), (32,16)>>> elapsed 0.012913 sec\n",
            "Arrays match.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include \"../common/common.h\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * This example demonstrates a simple vector sum on the GPU and on the host.\n",
        " * sumArraysOnGPU splits the work of the vector sum across CUDA threads on the\n",
        " * GPU. A 1D thread block and 1D grid are used. sumArraysOnHost sequentially\n",
        " * iterates through vector elements on the host.\n",
        " */\n",
        "\n",
        "void initialData(float *ip, const int size)\n",
        "{\n",
        "    int i;\n",
        "\n",
        "    for(i = 0; i < size; i++)\n",
        "    {\n",
        "        ip[i] = (float)(rand() & 0xFF ) / 10.0f;\n",
        "    }\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "void sumMatrixOnHost(float *A, float *B, float *C, const int nx,\n",
        "                     const int ny)\n",
        "{\n",
        "    float *ia = A;\n",
        "    float *ib = B;\n",
        "    float *ic = C;\n",
        "\n",
        "    for (int iy = 0; iy < ny; iy++)\n",
        "    {\n",
        "        for (int ix = 0; ix < nx; ix++)\n",
        "        {\n",
        "            ic[ix] = ia[ix] + ib[ix];\n",
        "\n",
        "        }\n",
        "\n",
        "        ia += nx;\n",
        "        ib += nx;\n",
        "        ic += nx;\n",
        "    }\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "\n",
        "void checkResult(float *hostRef, float *gpuRef, const int N)\n",
        "{\n",
        "    double epsilon = 1.0E-8;\n",
        "    bool match = 1;\n",
        "\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        if (abs(hostRef[i] - gpuRef[i]) > epsilon)\n",
        "        {\n",
        "            match = 0;\n",
        "            printf(\"host %f gpu %f\\n\", hostRef[i], gpuRef[i]);\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (match)\n",
        "        printf(\"Arrays match.\\n\\n\");\n",
        "    else\n",
        "        printf(\"Arrays do not match.\\n\\n\");\n",
        "}\n",
        "\n",
        "// grid 1D block 1D\n",
        "__global__ void sumMatrixOnGPU1D(float *MatA, float *MatB, float *MatC, int nx,\n",
        "                                 int ny)\n",
        "{\n",
        "    unsigned int ix = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    if (ix < nx )\n",
        "        for (int iy = 0; iy < ny; iy++)\n",
        "        {\n",
        "            int idx = iy * nx + ix;\n",
        "            MatC[idx] = MatA[idx] + MatB[idx];\n",
        "        }\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    printf(\"%s Starting...\\n\", argv[0]);\n",
        "\n",
        "    // set up device\n",
        "    int dev = 0;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
        "    printf(\"Using Device %d: %s\\n\", dev, deviceProp.name);\n",
        "    CHECK(cudaSetDevice(dev));\n",
        "\n",
        "    // set up data size of matrix\n",
        "    int nx = 1 << 14;\n",
        "    int ny = 1 << 14;\n",
        "\n",
        "    int nxy = nx * ny;\n",
        "    int nBytes = nxy * sizeof(float);\n",
        "    printf(\"Matrix size: nx %d ny %d\\n\", nx, ny);\n",
        "\n",
        "    // malloc host memory\n",
        "    float *h_A, *h_B, *hostRef, *gpuRef;\n",
        "    h_A = (float *)malloc(nBytes);\n",
        "    h_B = (float *)malloc(nBytes);\n",
        "    hostRef = (float *)malloc(nBytes);\n",
        "    gpuRef = (float *)malloc(nBytes);\n",
        "\n",
        "    // initialize data at host side\n",
        "    double iStart = seconds();\n",
        "    initialData(h_A, nxy);\n",
        "    initialData(h_B, nxy);\n",
        "    double iElaps = seconds() - iStart;\n",
        "    printf(\"initialize matrix elapsed %f sec\\n\", iElaps);\n",
        "\n",
        "    memset(hostRef, 0, nBytes);\n",
        "    memset(gpuRef, 0, nBytes);\n",
        "\n",
        "    // add matrix at host side for result checks\n",
        "    iStart = seconds();\n",
        "    sumMatrixOnHost(h_A, h_B, hostRef, nx, ny);\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"sumMatrixOnHost elapsed %f sec\\n\", iElaps);\n",
        "\n",
        "    // malloc device global memory\n",
        "    float *d_MatA, *d_MatB, *d_MatC;\n",
        "    CHECK(cudaMalloc((void **)&d_MatA, nBytes));\n",
        "    CHECK(cudaMalloc((void **)&d_MatB, nBytes));\n",
        "    CHECK(cudaMalloc((void **)&d_MatC, nBytes));\n",
        "\n",
        "    // transfer data from host to device\n",
        "    CHECK(cudaMemcpy(d_MatA, h_A, nBytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaMemcpy(d_MatB, h_B, nBytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // invoke kernel at host side\n",
        "    int dimx = 128;\n",
        "    dim3 block(dimx, 1);\n",
        "    dim3 grid((nx + block.x - 1) / block.x, 1);\n",
        "\n",
        "    iStart = seconds();\n",
        "    sumMatrixOnGPU1D<<<grid, block>>>(d_MatA, d_MatB, d_MatC, nx, ny);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"sumMatrixOnGPU1D <<<(%d,%d), (%d,%d)>>> elapsed %f sec\\n\", grid.x,\n",
        "           grid.y,\n",
        "           block.x, block.y, iElaps);\n",
        "\n",
        "    // check kernel error\n",
        "    CHECK(cudaGetLastError());\n",
        "\n",
        "    // copy kernel result back to host side\n",
        "    CHECK(cudaMemcpy(gpuRef, d_MatC, nBytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // check device results\n",
        "    checkResult(hostRef, gpuRef, nxy);\n",
        "\n",
        "    // free device global memory\n",
        "    CHECK(cudaFree(d_MatA));\n",
        "    CHECK(cudaFree(d_MatB));\n",
        "    CHECK(cudaFree(d_MatC));\n",
        "\n",
        "    // free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(hostRef);\n",
        "    free(gpuRef);\n",
        "\n",
        "    // reset device\n",
        "    CHECK(cudaDeviceReset());\n",
        "\n",
        "    return (0);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjZquyuPqvcR",
        "outputId": "a67f276b-b6e1-4acf-e005-d0aa2888343a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/tmp_4iqo0gr/6a29d5e6-276a-4a25-ba01-862142ab046a.out Starting...\n",
            "Using Device 0: Tesla T4\n",
            "Matrix size: nx 16384 ny 16384\n",
            "initialize matrix elapsed 14.306657 sec\n",
            "sumMatrixOnHost elapsed 0.868265 sec\n",
            "sumMatrixOnGPU1D <<<(128,1), (128,1)>>> elapsed 0.018929 sec\n",
            "Arrays match.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include \"../common/common.h\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * This example demonstrates a simple vector sum on the GPU and on the host.\n",
        " * sumArraysOnGPU splits the work of the vector sum across CUDA threads on the\n",
        " * GPU. A 1D thread block and 2D grid are used. sumArraysOnHost sequentially\n",
        " * iterates through vector elements on the host.\n",
        " */\n",
        "\n",
        "void initialData(float *ip, const int size)\n",
        "{\n",
        "    int i;\n",
        "\n",
        "    for(i = 0; i < size; i++)\n",
        "    {\n",
        "        ip[i] = (float)(rand() & 0xFF) / 10.0f;\n",
        "    }\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "void sumMatrixOnHost(float *A, float *B, float *C, const int nx,\n",
        "                     const int ny)\n",
        "{\n",
        "    float *ia = A;\n",
        "    float *ib = B;\n",
        "    float *ic = C;\n",
        "\n",
        "    for (int iy = 0; iy < ny; iy++)\n",
        "    {\n",
        "        for (int ix = 0; ix < nx; ix++)\n",
        "        {\n",
        "            ic[ix] = ia[ix] + ib[ix];\n",
        "\n",
        "        }\n",
        "\n",
        "        ia += nx;\n",
        "        ib += nx;\n",
        "        ic += nx;\n",
        "    }\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "\n",
        "void checkResult(float *hostRef, float *gpuRef, const int N)\n",
        "{\n",
        "    double epsilon = 1.0E-8;\n",
        "    bool match = 1;\n",
        "\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        if (abs(hostRef[i] - gpuRef[i]) > epsilon)\n",
        "        {\n",
        "            match = 0;\n",
        "            printf(\"host %f gpu %f\\n\", hostRef[i], gpuRef[i]);\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (match)\n",
        "        printf(\"Arrays match.\\n\\n\");\n",
        "    else\n",
        "        printf(\"Arrays do not match.\\n\\n\");\n",
        "}\n",
        "\n",
        "// grid 2D block 1D\n",
        "__global__ void sumMatrixOnGPUMix(float *MatA, float *MatB, float *MatC, int nx,\n",
        "                                  int ny)\n",
        "{\n",
        "    unsigned int ix = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    unsigned int iy = blockIdx.y;\n",
        "    unsigned int idx = iy * nx + ix;\n",
        "\n",
        "    if (ix < nx && iy < ny)\n",
        "        MatC[idx] = MatA[idx] + MatB[idx];\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    printf(\"%s Starting...\\n\", argv[0]);\n",
        "\n",
        "    // set up device\n",
        "    int dev = 0;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
        "    printf(\"Using Device %d: %s\\n\", dev, deviceProp.name);\n",
        "    CHECK(cudaSetDevice(dev));\n",
        "\n",
        "    // set up data size of matrix\n",
        "    int nx = 1 << 14;\n",
        "    int ny = 1 << 14;\n",
        "\n",
        "    int nxy = nx * ny;\n",
        "    int nBytes = nxy * sizeof(float);\n",
        "    printf(\"Matrix size: nx %d ny %d\\n\", nx, ny);\n",
        "\n",
        "    // malloc host memory\n",
        "    float *h_A, *h_B, *hostRef, *gpuRef;\n",
        "    h_A = (float *)malloc(nBytes);\n",
        "    h_B = (float *)malloc(nBytes);\n",
        "    hostRef = (float *)malloc(nBytes);\n",
        "    gpuRef = (float *)malloc(nBytes);\n",
        "\n",
        "    // initialize data at host side\n",
        "    double iStart = seconds();\n",
        "    initialData(h_A, nxy);\n",
        "    initialData(h_B, nxy);\n",
        "    double iElaps = seconds() - iStart;\n",
        "    printf(\"Matrix initialization elapsed %f sec\\n\", iElaps);\n",
        "\n",
        "    memset(hostRef, 0, nBytes);\n",
        "    memset(gpuRef, 0, nBytes);\n",
        "\n",
        "    // add matrix at host side for result checks\n",
        "    iStart = seconds();\n",
        "    sumMatrixOnHost(h_A, h_B, hostRef, nx, ny);\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"sumMatrixOnHost elapsed %f sec\\n\", iElaps);\n",
        "\n",
        "    // malloc device global memory\n",
        "    float *d_MatA, *d_MatB, *d_MatC;\n",
        "    CHECK(cudaMalloc((void **)&d_MatA, nBytes));\n",
        "    CHECK(cudaMalloc((void **)&d_MatB, nBytes));\n",
        "    CHECK(cudaMalloc((void **)&d_MatC, nBytes));\n",
        "\n",
        "    // transfer data from host to device\n",
        "    CHECK(cudaMemcpy(d_MatA, h_A, nBytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaMemcpy(d_MatB, h_B, nBytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // invoke kernel at host side\n",
        "    int dimx = 256;\n",
        "    dim3 block(dimx, 1);\n",
        "    dim3 grid((nx + block.x - 1) / block.x, ny);\n",
        "\n",
        "    iStart = seconds();\n",
        "    sumMatrixOnGPUMix<<<grid, block>>>(d_MatA, d_MatB, d_MatC, nx, ny);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"sumMatrixOnGPU2D <<<(%d,%d), (%d,%d)>>> elapsed %f sec\\n\", grid.x,\n",
        "           grid.y,\n",
        "           block.x, block.y, iElaps);\n",
        "    // check kernel error\n",
        "    CHECK(cudaGetLastError());\n",
        "\n",
        "    // copy kernel result back to host side\n",
        "    CHECK(cudaMemcpy(gpuRef, d_MatC, nBytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // check device results\n",
        "    checkResult(hostRef, gpuRef, nxy);\n",
        "\n",
        "    // free device global memory\n",
        "    CHECK(cudaFree(d_MatA));\n",
        "    CHECK(cudaFree(d_MatB));\n",
        "    CHECK(cudaFree(d_MatC));\n",
        "\n",
        "    // free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(hostRef);\n",
        "    free(gpuRef);\n",
        "\n",
        "    // reset device\n",
        "    CHECK(cudaDeviceReset());\n",
        "\n",
        "    return (0);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3MA9tYOriOk",
        "outputId": "7a3f6c08-8530-4d91-8d92-1889f40b947c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/tmp0m0wz8nk/6eeaf19b-5d2e-424f-9c95-6abdcdc8d7db.out Starting...\n",
            "Using Device 0: Tesla T4\n",
            "Matrix size: nx 16384 ny 16384\n",
            "Matrix initialization elapsed 11.583981 sec\n",
            "sumMatrixOnHost elapsed 0.866551 sec\n",
            "sumMatrixOnGPU2D <<<(64,16384), (256,1)>>> elapsed 0.012345 sec\n",
            "Arrays match.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include \"../common/common.h\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Display a variety of information on the first CUDA device in this system,\n",
        " * including driver version, runtime version, compute capability, bytes of\n",
        " * global memory, etc.\n",
        " */\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    printf(\"%s Starting...\\n\", argv[0]);\n",
        "\n",
        "    int deviceCount = 0;\n",
        "    cudaGetDeviceCount(&deviceCount);\n",
        "\n",
        "    if (deviceCount == 0)\n",
        "    {\n",
        "        printf(\"There are no available device(s) that support CUDA\\n\");\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        printf(\"Detected %d CUDA Capable device(s)\\n\", deviceCount);\n",
        "    }\n",
        "\n",
        "    int dev = 0, driverVersion = 0, runtimeVersion = 0;\n",
        "    CHECK(cudaSetDevice(dev));\n",
        "    cudaDeviceProp deviceProp;\n",
        "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
        "    printf(\"Device %d: \\\"%s\\\"\\n\", dev, deviceProp.name);\n",
        "\n",
        "    cudaDriverGetVersion(&driverVersion);\n",
        "    cudaRuntimeGetVersion(&runtimeVersion);\n",
        "    printf(\"  CUDA Driver Version / Runtime Version          %d.%d / %d.%d\\n\",\n",
        "           driverVersion / 1000, (driverVersion % 100) / 10,\n",
        "           runtimeVersion / 1000, (runtimeVersion % 100) / 10);\n",
        "    printf(\"  CUDA Capability Major/Minor version number:    %d.%d\\n\",\n",
        "           deviceProp.major, deviceProp.minor);\n",
        "    printf(\"  Total amount of global memory:                 %.2f GBytes (%llu \"\n",
        "           \"bytes)\\n\", (float)deviceProp.totalGlobalMem / pow(1024.0, 3),\n",
        "           (unsigned long long)deviceProp.totalGlobalMem);\n",
        "    printf(\"  GPU Clock rate:                                %.0f MHz (%0.2f \"\n",
        "           \"GHz)\\n\", deviceProp.clockRate * 1e-3f,\n",
        "           deviceProp.clockRate * 1e-6f);\n",
        "    printf(\"  Memory Clock rate:                             %.0f Mhz\\n\",\n",
        "           deviceProp.memoryClockRate * 1e-3f);\n",
        "    printf(\"  Memory Bus Width:                              %d-bit\\n\",\n",
        "           deviceProp.memoryBusWidth);\n",
        "\n",
        "    if (deviceProp.l2CacheSize)\n",
        "    {\n",
        "        printf(\"  L2 Cache Size:                                 %d bytes\\n\",\n",
        "               deviceProp.l2CacheSize);\n",
        "    }\n",
        "\n",
        "    printf(\"  Max Texture Dimension Size (x,y,z)             1D=(%d), \"\n",
        "           \"2D=(%d,%d), 3D=(%d,%d,%d)\\n\", deviceProp.maxTexture1D,\n",
        "           deviceProp.maxTexture2D[0], deviceProp.maxTexture2D[1],\n",
        "           deviceProp.maxTexture3D[0], deviceProp.maxTexture3D[1],\n",
        "           deviceProp.maxTexture3D[2]);\n",
        "    printf(\"  Max Layered Texture Size (dim) x layers        1D=(%d) x %d, \"\n",
        "           \"2D=(%d,%d) x %d\\n\", deviceProp.maxTexture1DLayered[0],\n",
        "           deviceProp.maxTexture1DLayered[1], deviceProp.maxTexture2DLayered[0],\n",
        "           deviceProp.maxTexture2DLayered[1],\n",
        "           deviceProp.maxTexture2DLayered[2]);\n",
        "    printf(\"  Total amount of constant memory:               %lu bytes\\n\",\n",
        "           deviceProp.totalConstMem);\n",
        "    printf(\"  Total amount of shared memory per block:       %lu bytes\\n\",\n",
        "           deviceProp.sharedMemPerBlock);\n",
        "    printf(\"  Total number of registers available per block: %d\\n\",\n",
        "           deviceProp.regsPerBlock);\n",
        "    printf(\"  Warp size:                                     %d\\n\",\n",
        "           deviceProp.warpSize);\n",
        "    printf(\"  Maximum number of threads per multiprocessor:  %d\\n\",\n",
        "           deviceProp.maxThreadsPerMultiProcessor);\n",
        "    printf(\"  Maximum number of threads per block:           %d\\n\",\n",
        "           deviceProp.maxThreadsPerBlock);\n",
        "    printf(\"  Maximum sizes of each dimension of a block:    %d x %d x %d\\n\",\n",
        "           deviceProp.maxThreadsDim[0],\n",
        "           deviceProp.maxThreadsDim[1],\n",
        "           deviceProp.maxThreadsDim[2]);\n",
        "    printf(\"  Maximum sizes of each dimension of a grid:     %d x %d x %d\\n\",\n",
        "           deviceProp.maxGridSize[0],\n",
        "           deviceProp.maxGridSize[1],\n",
        "           deviceProp.maxGridSize[2]);\n",
        "    printf(\"  Maximum memory pitch:                          %lu bytes\\n\",\n",
        "           deviceProp.memPitch);\n",
        "\n",
        "    exit(EXIT_SUCCESS);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzdge10dsd06",
        "outputId": "88889bfb-81d2-40cb-8307-b4e68f68a7d7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/tmp8wqd5dw_/127fe5d9-f01a-44e8-bb35-69567d3e97bf.out Starting...\n",
            "Detected 1 CUDA Capable device(s)\n",
            "Device 0: \"Tesla T4\"\n",
            "  CUDA Driver Version / Runtime Version          12.0 / 11.8\n",
            "  CUDA Capability Major/Minor version number:    7.5\n",
            "  Total amount of global memory:                 14.75 GBytes (15835398144 bytes)\n",
            "  GPU Clock rate:                                1590 MHz (1.59 GHz)\n",
            "  Memory Clock rate:                             5001 Mhz\n",
            "  Memory Bus Width:                              256-bit\n",
            "  L2 Cache Size:                                 4194304 bytes\n",
            "  Max Texture Dimension Size (x,y,z)             1D=(131072), 2D=(131072,65536), 3D=(16384,16384,16384)\n",
            "  Max Layered Texture Size (dim) x layers        1D=(32768) x 2048, 2D=(32768,32768) x 2048\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Maximum number of threads per multiprocessor:  1024\n",
            "  Maximum number of threads per block:           1024\n",
            "  Maximum sizes of each dimension of a block:    1024 x 1024 x 64\n",
            "  Maximum sizes of each dimension of a grid:     2147483647 x 65535 x 65535\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include \"../common/common.h\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * This example demonstrates a simple vector sum on the GPU and on the host.\n",
        " * sumArraysOnGPU splits the work of the vector sum across CUDA threads on the\n",
        " * GPU. A 2D thread block and 2D grid are used. sumArraysOnHost sequentially\n",
        " * iterates through vector elements on the host.\n",
        " */\n",
        "\n",
        "void initialData(int *ip, const int size)\n",
        "{\n",
        "    int i;\n",
        "\n",
        "    for(i = 0; i < size; i++)\n",
        "    {\n",
        "        ip[i] = (int)(rand() & 0xFF);\n",
        "    }\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "void sumMatrixOnHost(int *A, int *B, int *C, const int nx,\n",
        "                     const int ny)\n",
        "{\n",
        "    int *ia = A;\n",
        "    int *ib = B;\n",
        "    int *ic = C;\n",
        "\n",
        "    for (int iy = 0; iy < ny; iy++)\n",
        "    {\n",
        "        for (int ix = 0; ix < nx; ix++)\n",
        "        {\n",
        "            ic[ix] = ia[ix] + ib[ix];\n",
        "\n",
        "        }\n",
        "\n",
        "        ia += nx;\n",
        "        ib += nx;\n",
        "        ic += nx;\n",
        "    }\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "\n",
        "void checkResult(int *hostRef, int *gpuRef, const int N)\n",
        "{\n",
        "    bool match = 1;\n",
        "\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        if (hostRef[i] != gpuRef[i])\n",
        "        {\n",
        "            match = 0;\n",
        "            printf(\"host %d gpu %d\\n\", hostRef[i], gpuRef[i]);\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (match)\n",
        "        printf(\"Arrays match.\\n\\n\");\n",
        "    else\n",
        "        printf(\"Arrays do not match.\\n\\n\");\n",
        "}\n",
        "\n",
        "// grid 2D block 2D\n",
        "__global__ void sumMatrixOnGPU2D(int *MatA, int *MatB, int *MatC, int nx,\n",
        "                                 int ny)\n",
        "{\n",
        "    unsigned int ix = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    unsigned int iy = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    unsigned int idx = iy * nx + ix;\n",
        "\n",
        "    if (ix < nx && iy < ny)\n",
        "        MatC[idx] = MatA[idx] + MatB[idx];\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    printf(\"%s Starting...\\n\", argv[0]);\n",
        "\n",
        "    // set up device\n",
        "    int dev = 0;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
        "    printf(\"Using Device %d: %s\\n\", dev, deviceProp.name);\n",
        "    CHECK(cudaSetDevice(dev));\n",
        "\n",
        "    // set up data size of matrix\n",
        "    int nx = 1 << 12;\n",
        "    int ny = 1 << 12;\n",
        "\n",
        "    int nxy = nx * ny;\n",
        "    int nBytes = nxy * sizeof(int);\n",
        "    printf(\"Matrix size: nx %d ny %d\\n\", nx, ny);\n",
        "\n",
        "    // malloc host memory\n",
        "    int *h_A, *h_B, *hostRef, *gpuRef;\n",
        "    h_A = (int *)malloc(nBytes);\n",
        "    h_B = (int *)malloc(nBytes);\n",
        "    hostRef = (int *)malloc(nBytes);\n",
        "    gpuRef = (int *)malloc(nBytes);\n",
        "\n",
        "    // initialize data at host side\n",
        "    double iStart = seconds();\n",
        "    initialData(h_A, nxy);\n",
        "    initialData(h_B, nxy);\n",
        "    double iElaps = seconds() - iStart;\n",
        "    printf(\"Matrix initialization elapsed %f sec\\n\", iElaps);\n",
        "\n",
        "    memset(hostRef, 0, nBytes);\n",
        "    memset(gpuRef, 0, nBytes);\n",
        "\n",
        "    // add matrix at host side for result checks\n",
        "    iStart = seconds();\n",
        "    sumMatrixOnHost(h_A, h_B, hostRef, nx, ny);\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"sumMatrixOnHost elapsed %f sec\\n\", iElaps);\n",
        "\n",
        "    // malloc device global memory\n",
        "    int *d_MatA, *d_MatB, *d_MatC;\n",
        "    CHECK(cudaMalloc((void **)&d_MatA, nBytes));\n",
        "    CHECK(cudaMalloc((void **)&d_MatB, nBytes));\n",
        "    CHECK(cudaMalloc((void **)&d_MatC, nBytes));\n",
        "\n",
        "    // transfer data from host to device\n",
        "    CHECK(cudaMemcpy(d_MatA, h_A, nBytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaMemcpy(d_MatB, h_B, nBytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // invoke kernel at host side\n",
        "    int dimx = 64;\n",
        "    int dimy = 2;\n",
        "    dim3 block(dimx, dimy);\n",
        "    dim3 grid((nx + block.x - 1) / block.x, (ny + block.y - 1) / block.y);\n",
        "\n",
        "    iStart = seconds();\n",
        "    sumMatrixOnGPU2D<<<grid, block>>>(d_MatA, d_MatB, d_MatC, nx, ny);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"sumMatrixOnGPU2D <<<(%d,%d), (%d,%d)>>> elapsed %f sec\\n\", grid.x,\n",
        "           grid.y,\n",
        "           block.x, block.y, iElaps);\n",
        "    // check kernel error\n",
        "    CHECK(cudaGetLastError());\n",
        "\n",
        "    // copy kernel result back to host side\n",
        "    CHECK(cudaMemcpy(gpuRef, d_MatC, nBytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // check device results\n",
        "    checkResult(hostRef, gpuRef, nxy);\n",
        "\n",
        "    // free device global memory\n",
        "    CHECK(cudaFree(d_MatA));\n",
        "    CHECK(cudaFree(d_MatB));\n",
        "    CHECK(cudaFree(d_MatC));\n",
        "\n",
        "    // free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(hostRef);\n",
        "    free(gpuRef);\n",
        "\n",
        "    // reset device\n",
        "    CHECK(cudaDeviceReset());\n",
        "\n",
        "    return (0);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXX6zM79wMnP",
        "outputId": "487ab95b-c5a7-4856-9e3e-1ddd6aa7b6ea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/tmpcv5k8_cb/d58d873e-7d43-4d72-bc1d-86d4161b93ff.out Starting...\n",
            "Using Device 0: Tesla T4\n",
            "Matrix size: nx 4096 ny 4096\n",
            "Matrix initialization elapsed 0.944288 sec\n",
            "sumMatrixOnHost elapsed 0.098832 sec\n",
            "sumMatrixOnGPU2D <<<(64,2048), (64,2)>>> elapsed 0.000862 sec\n",
            "Arrays match.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile simpleDivergence.cu\n",
        "\n",
        "#include \"../common/common.h\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * simpleDivergence demonstrates divergent code on the GPU and its impact on\n",
        " * performance and CUDA metrics.\n",
        " */\n",
        "\n",
        "__global__ void mathKernel1(float *c)\n",
        "{\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float ia, ib;\n",
        "    ia = ib = 0.0f;\n",
        "\n",
        "    if (tid % 2 == 0)\n",
        "    {\n",
        "        ia = 100.0f;\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ib = 200.0f;\n",
        "    }\n",
        "\n",
        "    c[tid] = ia + ib;\n",
        "}\n",
        "\n",
        "__global__ void mathKernel2(float *c)\n",
        "{\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float ia, ib;\n",
        "    ia = ib = 0.0f;\n",
        "\n",
        "    if ((tid / warpSize) % 2 == 0)\n",
        "    {\n",
        "        ia = 100.0f;\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ib = 200.0f;\n",
        "    }\n",
        "\n",
        "    c[tid] = ia + ib;\n",
        "}\n",
        "\n",
        "__global__ void mathKernel3(float *c)\n",
        "{\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float ia, ib;\n",
        "    ia = ib = 0.0f;\n",
        "\n",
        "    bool ipred = (tid % 2 == 0);\n",
        "\n",
        "    if (ipred)\n",
        "    {\n",
        "        ia = 100.0f;\n",
        "    }\n",
        "\n",
        "    if (!ipred)\n",
        "    {\n",
        "        ib = 200.0f;\n",
        "    }\n",
        "\n",
        "    c[tid] = ia + ib;\n",
        "}\n",
        "\n",
        "__global__ void mathKernel4(float *c)\n",
        "{\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float ia, ib;\n",
        "    ia = ib = 0.0f;\n",
        "\n",
        "    int itid = tid >> 5;\n",
        "\n",
        "    if (itid & 0x01 == 0)\n",
        "    {\n",
        "        ia = 100.0f;\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ib = 200.0f;\n",
        "    }\n",
        "\n",
        "    c[tid] = ia + ib;\n",
        "}\n",
        "\n",
        "__global__ void warmingup(float *c)\n",
        "{\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float ia, ib;\n",
        "    ia = ib = 0.0f;\n",
        "\n",
        "    if ((tid / warpSize) % 2 == 0)\n",
        "    {\n",
        "        ia = 100.0f;\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ib = 200.0f;\n",
        "    }\n",
        "\n",
        "    c[tid] = ia + ib;\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    // set up device\n",
        "    int dev = 0;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
        "    printf(\"%s using Device %d: %s\\n\", argv[0], dev, deviceProp.name);\n",
        "\n",
        "    // set up data size\n",
        "    int size = 64;\n",
        "    int blocksize = 64;\n",
        "\n",
        "    if(argc > 1) blocksize = atoi(argv[1]);\n",
        "\n",
        "    if(argc > 2) size      = atoi(argv[2]);\n",
        "\n",
        "    printf(\"Data size %d \", size);\n",
        "\n",
        "    // set up execution configuration\n",
        "    dim3 block (blocksize, 1);\n",
        "    dim3 grid  ((size + block.x - 1) / block.x, 1);\n",
        "    printf(\"Execution Configure (block %d grid %d)\\n\", block.x, grid.x);\n",
        "\n",
        "    // allocate gpu memory\n",
        "    float *d_C;\n",
        "    size_t nBytes = size * sizeof(float);\n",
        "    CHECK(cudaMalloc((float**)&d_C, nBytes));\n",
        "\n",
        "    // run a warmup kernel to remove overhead\n",
        "    size_t iStart, iElaps;\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    warmingup<<<grid, block>>>(d_C);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"warmup      <<< %4d %4d >>> elapsed %f sec \\n\", grid.x, block.x,\n",
        "           iElaps );\n",
        "    CHECK(cudaGetLastError());\n",
        "\n",
        "    // run kernel 1\n",
        "    iStart = seconds();\n",
        "    mathKernel1<<<grid, block>>>(d_C);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"mathKernel1 <<< %4d %4d >>> elapsed %f sec \\n\", grid.x, block.x,\n",
        "           iElaps );\n",
        "    CHECK(cudaGetLastError());\n",
        "\n",
        "    // run kernel 3\n",
        "    iStart = seconds();\n",
        "    mathKernel2<<<grid, block>>>(d_C);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"mathKernel2 <<< %4d %4d >>> elapsed %f sec \\n\", grid.x, block.x,\n",
        "           iElaps );\n",
        "    CHECK(cudaGetLastError());\n",
        "\n",
        "    // run kernel 3\n",
        "    iStart = seconds();\n",
        "    mathKernel3<<<grid, block>>>(d_C);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"mathKernel3 <<< %4d %4d >>> elapsed %f sec \\n\", grid.x, block.x,\n",
        "           iElaps);\n",
        "    CHECK(cudaGetLastError());\n",
        "\n",
        "    // run kernel 4\n",
        "    iStart = seconds();\n",
        "    mathKernel4<<<grid, block>>>(d_C);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"mathKernel4 <<< %4d %4d >>> elapsed %f sec \\n\", grid.x, block.x,\n",
        "           iElaps);\n",
        "    CHECK(cudaGetLastError());\n",
        "\n",
        "    // free gpu memory and reset divece\n",
        "    CHECK(cudaFree(d_C));\n",
        "    CHECK(cudaDeviceReset());\n",
        "    return EXIT_SUCCESS;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWJya8r9Hw8y",
        "outputId": "66f1bb0a-b0cb-45b9-9321-5c2412bf26fc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting simpleDivergence.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc simpleDivergence.cu -o simpleDivergence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVcV1QaIIEKC",
        "outputId": "3e82590c-a273-4989-ead7-bcc4fa0e0afe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[KsimpleDivergence.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint main(int, char**)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[KsimpleDivergence.cu:142:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%f\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kdouble\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wformat=\u0007-Wformat=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  142 |     pri\u001b[01;35m\u001b[Kntf(\"warmup      <<< %4d %4d >>> elapsed %f sec\u001b[m\u001b[K \\n\", grid.x, block\u001b[32m\u001b[K.x,\u001b[m\u001b[K\n",
            "      |        \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                   \u001b[32m\u001b[K~~~\u001b[m\u001b[K   \n",
            "      |                                                                          \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                                          \u001b[32m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[KsimpleDivergence.cu:151:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%f\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kdouble\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wformat=\u0007-Wformat=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  151 |     pri\u001b[01;35m\u001b[Kntf(\"mathKernel1 <<< %4d %4d >>> elapsed %f sec\u001b[m\u001b[K \\n\", grid.x, block\u001b[32m\u001b[K.x,\u001b[m\u001b[K\n",
            "      |        \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                   \u001b[32m\u001b[K~~~\u001b[m\u001b[K   \n",
            "      |                                                                          \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                                          \u001b[32m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[KsimpleDivergence.cu:160:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%f\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kdouble\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wformat=\u0007-Wformat=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  160 |     pri\u001b[01;35m\u001b[Kntf(\"mathKernel2 <<< %4d %4d >>> elapsed %f sec\u001b[m\u001b[K \\n\", grid.x, block\u001b[32m\u001b[K.x,\u001b[m\u001b[K\n",
            "      |        \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                   \u001b[32m\u001b[K~~~\u001b[m\u001b[K   \n",
            "      |                                                                          \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                                          \u001b[32m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[KsimpleDivergence.cu:169:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%f\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kdouble\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wformat=\u0007-Wformat=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  169 |     pri\u001b[01;35m\u001b[Kntf(\"mathKernel3 <<< %4d %4d >>> elapsed %f sec\u001b[m\u001b[K \\n\", grid.x, block\u001b[32m\u001b[K.x,\u001b[m\u001b[K\n",
            "      |        \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                   \u001b[32m\u001b[K~~~\u001b[m\u001b[K   \n",
            "      |                                                                          \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                                          \u001b[32m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[KsimpleDivergence.cu:178:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%f\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kdouble\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wformat=\u0007-Wformat=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  178 |     pri\u001b[01;35m\u001b[Kntf(\"mathKernel4 <<< %4d %4d >>> elapsed %f sec\u001b[m\u001b[K \\n\", grid.x, block\u001b[32m\u001b[K.x,\u001b[m\u001b[K\n",
            "      |        \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                   \u001b[32m\u001b[K~~~\u001b[m\u001b[K   \n",
            "      |                                                                          \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                                          \u001b[32m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./simpleDivergence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJWlUyWSIpWo",
        "outputId": "50dbbf95-d1bd-47ab-cf1b-199cd33f70d9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./simpleDivergence using Device 0: Tesla T4\n",
            "Data size 64 Execution Configure (block 64 grid 1)\n",
            "warmup      <<<    1   64 >>> elapsed 0.000000 sec \n",
            "mathKernel1 <<<    1   64 >>> elapsed 0.000000 sec \n",
            "mathKernel2 <<<    1   64 >>> elapsed 0.000000 sec \n",
            "mathKernel3 <<<    1   64 >>> elapsed 0.000000 sec \n",
            "mathKernel4 <<<    1   64 >>> elapsed 0.000000 sec \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof"
      ],
      "metadata": {
        "id": "F79bkvS8JHNG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}